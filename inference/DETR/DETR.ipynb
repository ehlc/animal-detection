{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChwEKeYgeFbH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "from PIL import Image, ImageDraw\n",
        "import torchvision.transforms as T\n",
        "import torchvision.ops as ops\n",
        "import torchvision.transforms.functional as F\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def detectar_y_dibujar_detr(image_path, model_path='aerial_animals_DETR.pth', score_threshold=0.1, iou_threshold=0.1):\n",
        "    # Cargar processor y modelo fine-tuneado\n",
        "    processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
        "    #model = DetrForObjectDetection.from_pretrained(model_path)\n",
        "\n",
        "\n",
        "    # Cargar modelo con num_labels correcto y permitir discrepancias de tamaños\n",
        "    model = DetrForObjectDetection.from_pretrained(\n",
        "        \"facebook/detr-resnet-50\",\n",
        "        num_labels=6,  # Ajusta al número de clases de tu entrenamiento\n",
        "        ignore_mismatched_sizes=True\n",
        "    )\n",
        "\n",
        "    # Cargar pesos entrenados\n",
        "    model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
        "\n",
        "\n",
        "    DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Cargar imagen\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = processor(images=image, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Obtener predicciones procesadas\n",
        "    target_sizes = torch.tensor([image.size[::-1]], device=DEVICE)  # (H, W)\n",
        "    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=score_threshold)[0]\n",
        "\n",
        "    # Aplicar NMS si se desea (DETR no lo aplica por diseño)\n",
        "    boxes = results[\"boxes\"]\n",
        "    scores = results[\"scores\"]\n",
        "    labels = results[\"labels\"]\n",
        "\n",
        "    keep_nms = ops.nms(boxes, scores, iou_threshold)\n",
        "    boxes = boxes[keep_nms]\n",
        "    labels = labels[keep_nms]\n",
        "\n",
        "    # Dibujar resultados sobre imagen\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    for box in boxes:\n",
        "\n",
        "        x1, y1, x2, y2 = box.tolist()\n",
        "        draw.rectangle([x1, y1, x2, y2], outline=\"blue\", width=10)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "\n",
        "    # Convertir imagen con cajas a tensor\n",
        "    output_tensor = T.ToTensor()(image)\n",
        "    plt.tight_layout()\n",
        "    plt.imshow(F.to_pil_image(output_tensor))\n",
        "    plt.axis('off')\n",
        "\n",
        "    buf = BytesIO()\n",
        "    fig.savefig(buf, format='jpeg', bbox_inches='tight', pad_inches=0)\n",
        "    buf.seek(0)\n",
        "    plt.close(fig)  # Avoid displaying\n",
        "\n",
        "\n",
        "    image = Image.open(buf).copy()\n",
        "    buf.close()\n",
        "    image_array = np.array(image)\n",
        "    # plt.show()\n",
        "\n",
        "    return image_array, len(boxes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "image_array, num_boxes = detectar_y_dibujar_detr('19c019842e984b53a75251fa6a4c54e05682b762.JPG')\n",
        "image_array\n",
        "# plt.tight_layout()\n",
        "# plt.imshow(F.to_pil_image(output_tensor))\n",
        "# plt.axis('off')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "output_tensor = detectar_y_dibujar_detr('308982734a08ca0092bd98b963655acea0a162b0.JPG')\n",
        "plt.imshow(F.to_pil_image(output_tensor))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xvfe4Wu-elcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bz_DKu7ntTFF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1wV7J0KMAoVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DSmKPho0AoXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zMWOeurcAoZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rF-Wp4ZgAob-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}